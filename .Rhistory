ggplot(dat = ds, aes(y = lumm group = type)) +
geom_bar()
ggplot(dat = ds, aes(y = lum, group = type)) +
geom_bar()
ggplot(dat = ds, aes(x =  type)) +
geom_bar()
# the number of wells per place
ggplot(dat = ds, aes(x =  type)) +
geom_bar() +
labs(title = 'number of wells per plate')
# the number of wells per place
ggplot(dat = ds, aes(x =  type)) +
geom_bar() +
labs(title = 'number of wells per plate',
y = 'number of wells',
x = 'chemiluminescence')
setwd("/Volumes/GoogleDrive/Team Drives/Website/blog/beauty")
install.packages("Quandl")
library(Quandl)
example("Quandl")
mydata = Quandl("FRED/GDP")
head(mydata)
mydata = Quandl("FRED/GDP", type="raw")
setwd("/Volumes/GoogleDrive/Team Drives/Website/blog/beauty")
pacman::p_load(ggplot2, magrittr, treemapify, dplyr)
setwd("/Volumes/GoogleDrive/Team Drives/Website/blog/beauty")
df = read.csv('products_splash.csv', stringsAsFactors = F)
head(df)
df  %<>% filter(itemSize != "" | itemSizeUOM != "")
head(df)
#437 brands
table(df$brand)
df$itemSize = as.numeric(df$itemSize)
#df$itemSize = as.numeric(df$itemSize)
summary(df$itemSize)
# The category variable needs to be broken up
df[,20]
# The category variable needs to be broken up
df(,10)
# The category variable needs to be broken up
head(df[,10])
# The category variable needs to be broken up
head(df, 10)
# The category variable needs to be broken up
head(df, 20)
# The category variable needs to be broken up
head(20, df)
# The category variable needs to be broken up
df[,1]
# The category variable needs to be broken up
df[20,1]
# The category variable needs to be broken up
df[1:20,1]
pacman::p_load(ggplot2, magrittr, tidyr, treemapify, dplyr)
#
df1 = df %>% separate(category, c("general", "type", 'subtype'))
#
df1 = df %>% separate(category, c("general", "type", 'subtype'), sep = ':')
head(df1)
table(df1$subtype)
table(df1$type)
#
df1 = df %>% separate(category, c("general", "type", 'subtype'), sep = ':',
extra = "drop", fill = "right")
test = df1 %>% filter(category == 'makeup' | type == 'makeup' | subtype == 'makeup')
test = df1 %>% filter(general == 'makeup' | type == 'makeup' | subtype == 'makeup')
test[1:20, 1]
test[,20]
head(df)
head(test)
View(test)
tot = df %>% group_by(brand) %>%
tally() %>%
top_n(100) %>%
arrange(desc(n)) %>%
data.frame
tot[1:25,]
rm(df1, test, tot)
#
df1 = df %>% separate(category, c("general", "type", 'subtype'), sep = ':',
extra = "drop", fill = "right") %>%
filter(general == 'makeup')
head(df1)
table(df1$type)
df = read.csv('products_splash.csv', stringsAsFactors = F)
#437 brands
table(df$brand)
# The category variable needs to be broken up at the semi-colon
df[1:20,1]
#
df1 = df %>% separate(category, c("general", "type", 'subtype'), sep = ':',
extra = "drop", fill = "right") %>%
filter(general == 'makeup')
table(df1$type)
filter(df1, type == 'lips')
test = filter(df1, type == 'lips')
table(test$brand)
rm(test)
makeup = df1 %>% filter(general == 'makeup' | type == 'makeup' | subtype == 'lips')
lips = df %>% filter(subtype == 'lips')
#
df1 = df %>% separate(category, c("general", "type", 'subtype'), sep = ':',
extra = "drop", fill = "right")
lips = df %>% filter(subtype == 'lips')
lips = df1 %>% filter(subtype == 'lips')
table(df1$subtype)
summary(df1)
#
df1 = df %>% separate(category, c("general", "type", 'subtype'), sep = ':',
extra = "drop", fill = "right") %>%
as.factor(general)
#
df1 = df %>% separate(category, c("general", "type", 'subtype'), sep = ':',
extra = "drop", fill = "right") %>%
as.factor(df1$general)
#
df1 = df %>% separate(category, c("general", "type", 'subtype'), sep = ':',
extra = "drop", fill = "right") %>%
factor(general)
View(df1)
#
df1 = df %>% separate(category, c("general", "type", 'subtype'), sep = ':',
extra = "drop", fill = "right") %>%
factor(general, type)
#
df1 = df %>% separate(category, c("general", "type", 'subtype'), sep = ':',
extra = "drop", fill = "right")
df1$general = as.factor(df1$general)
table(df1$general)
df1$type = as.factor(df1$type)
table(df1$type)
summary(df1)
df1$subtype = as.factor(df1$subtype)
table(df1$subtype)
table(df1$subtype)
summary(df1)
df1$general = as.factor(df1$general)
table(df1$general)
table(df1$subtype)
table(df1$type)
df2 = read.csv('products.csv', stringsAsFactors = F)
#df$itemSize = as.numeric(df$itemSize)
summary(df$itemSize)
table(df2$brand)
#437 brands
table(df$brand)
# The category variable needs to be broken up at the semi-colon
df[1:20,1]
df2[1:20,1]
df$itemSize = as.numeric(df$itemSize)
df2$itemSize = as.numeric(df2$itemSize)
summary(df$itemSize)
summary(df2$itemSize)
View(makeup)
table(makeup$brand)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(devtools)
install_github("tierneyn/visdat")
?visdat
library(RGraphics) # support of the "R graphics" book, on CRAN
pacman::p_load(RGraphics)
library(RGraphics) # support of the "R graphics" book, on CRAN
library(gridExtra)
g1 <- tableGrob(head(iris))
string <- "
This famous (Fisher's or Anderson's) iris data set gives the
measurements in centimeters of the variables sepal length and width
and petal length and width, respectively, for 50 flowers from each of
3 species of iris. The species are Iris setosa, versicolor, and
virginica.
"
g2 <- splitTextGrob(string)
#"Sepal.Length" "Sepal.Width"  "Petal.Length" "Petal.Width"  "Species"
g3 <- qplot(Sepal.Length,  Petal.Length, data=iris, colour=Species)
grid.arrange(g1, g2, g3, ncol=1, top="The iris data")
?qplot
library(ggplot2)
#"Sepal.Length" "Sepal.Width"  "Petal.Length" "Petal.Width"  "Species"
g3 <- qplot(Sepal.Length,  Petal.Length, data=iris, colour=Species)
grid.arrange(g1, g2, g3, ncol=1, top="The iris data")
dat <- data.frame(Position=rep(c("President", "Vice"), each = 3),
Name = c("Washington", rep(c("Adams", "Jefferson"), 2), "Burr"),
start = c("1789-03-29", "1797-02-03", "1801-02-03"),
end = c("1797-02-03", "1801-02-03", "1809-02-03"),
color = c('#cbb69d', '#603913', '#c69c6e'),
fontcolor = c("black", "white", "black"))
dat
vistime(data)
data <- read.csv(text="event,group,start,end,color
Phase 1,Project,2016-12-22,2016-12-23,#c8e6c9
Phase 2,Project,2016-12-23,2016-12-29,#a5d6a7
Phase 3,Project,2016-12-29,2017-01-06,#fb8c00
Phase 4,Project,2017-01-06,2017-02-02,#DD4B39
1-217.0,category 2,2016-12-27,2016-12-27,#90caf9
3-200,category 1,2016-12-25,2016-12-25,#1565c0
3-330,category 1,2016-12-25,2016-12-25,#1565c0
3-223,category 1,2016-12-28,2016-12-28,#1565c0
3-225,category 1,2016-12-28,2016-12-28,#1565c0
3-226,category 1,2016-12-28,2016-12-28,#1565c0
3-226,category 1,2017-01-19,2017-01-19,#1565c0
3-330,category 1,2017-01-19,2017-01-19,#1565c0
4-399.7,moon rising,2017-01-13,2017-01-13,#f44336
8-831.0,sundowner drink,2017-01-17,2017-01-17,#8d6e63
9-984.1,birthday party,2016-12-22,2016-12-22,#90a4ae
F01.9,Meetings,2016-12-26,2016-12-26,#e8a735
Z71,Meetings,2017-01-12,2017-01-12,#e8a735
B95.7,Meetings,2017-01-15,2017-01-15,#e8a735
T82.7,Meetings,2017-01-15,2017-01-15,#e8a735
Room 334,Team 1,2016-12-22,2016-12-28,#DEEBF7
Room 335,Team 1,2016-12-28,2017-01-05,#C6DBEF
Room 335,Team 1,2017-01-05,2017-01-23,#9ECAE1
Group 1,Team 2,2016-12-22,2016-12-28,#E5F5E0
Group 2,Team 2,2016-12-28,2017-01-23,#C7E9C0")
library(visdat)
?visdat
library(vistime)
pacman::p_load(vistime)
rm(g1, g2, g3)
vistime(data)
head(data)
View(data)
View(dat)
vistime(dat, events="Position", groups="Name", title="Presidents of the USA")
View(data)
pacman::p_load(read.csv)
ds = read.csv('/Volumes/GoogleDrive/Team Drives/Admin-Business-Confidential/business-plan/data/excel/timeline.csv')
vistime(ds)
vistime(ds, group = group, event = event)
vistime(ds, group = 'group', event = 'event'')
vistime(ds, group = 'group', event = 'event'')
)
vistime(ds, group = 'group', event = 'event')
vistime(ds, group = 'event', event = 'group')
str(ds)
View(ds)
View(ds)
ds1 = ds %>% select(-group)
vistime(ds1)
ds = read.csv('/Volumes/GoogleDrive/Team Drives/Admin-Business-Confidential/business-plan/data/excel/timeline.csv')
vistime(ds1)
vistime(ds)
View(ds)
data <- read.csv(text="event,group,start,end,color
Value Mission,Phase,2016-12-22,2016-12-23,#c8e6c9
Minimum Value Product,Phase,2016-12-23,2016-12-29,#a5d6a7
Product Market Fit,Phase,2016-12-29,2017-01-06,#fb8c00
Scaling,Phase,2017-01-06,2017-02-02,#DD4B39
1-217.0,category 2,2016-12-27,2016-12-27,#90caf9
3-200,category 1,2016-12-25,2016-12-25,#1565c0")
vistime(data)
data <- read.csv(text="event,group,start,end,color
Value Mission,Phase,2017-07-01,2017-09-01,#c8e6c9
Minimum Value Product,Phase,2017-09-02,2018-01-01,#a5d6a7
Product Market Fit,Phase,2018-01-02,2018-07-30,#fb8c00
Scaling,Phase,2018-08-01,2018-12-30,#DD4B39
1-217.0,category 2,2019-12-27,2019-12-27,#90caf9
3-200,category 1,2019-12-25,2019-12-25,#1565c0")
vistime(data)
data <- read.csv(text="event,group,start,end,color
Pre-startup,Phase,2017-07-01,2017-09-01,#c8e6c9
Startup,Phase,2017-09-02,2018-01-01,#a5d6a7
Growth,Phase,2018-01-02,2018-07-30,#fb8c00
Scaling,Phase,2018-08-01,2018-12-30,#DD4B39
1-217.0,category 2,2019-12-27,2019-12-27,#90caf9
3-200,category 1,2019-12-25,2019-12-25,#1565c0")
vistime(data)
data <- read.csv(text="event,group,start,end,color
Pre-startup,Phase,2017-07-01,2018-01-01,#c8e6c9
Startup,Phase,2018-01-02,2018-12-30,#a5d6a7
Growth,Phase,2019-01-01,2019-12-30,#fb8c00
Value Mission,Phase,2017-07-01,2017-09-01,#c8e6c9
Minimum Value Product,Phase,2017-09-02,2018-01-01,#a5d6a7
Product Market Fit,Phase,2018-01-02,2018-07-30,#fb8c00
Scaling,Phase,2018-08-01,2018-12-30,#DD4B39
1-217.0,category 2,2019-12-27,2019-12-27,#90caf9
3-200,category 1,2019-12-25,2019-12-25,#1565c0")
vistime(data)
data <- read.csv(text="event,group,start,end,color
Pre-startup,Phase,2017-07-01,2018-01-01,#c8e6c9
Startup,Phase,2018-01-02,2018-12-30,#a5d6a7
Growth,Phase,2019-01-01,2019-12-30,#fb8c00
"",Value Mission,2017-07-01,2017-09-01,#c8e6c9
Minimum Value Product,Phase,2017-09-02,2018-01-01,#a5d6a7
Product Market Fit,Phase,2018-01-02,2018-07-30,#fb8c00
Scaling,Phase,2018-08-01,2018-12-30,#DD4B39
1-217.0,category 2,2019-12-27,2019-12-27,#90caf9
3-200,category 1,2019-12-25,2019-12-25,#1565c0")
vistime(data)
data <- read.csv(text="event,group,start,end,color
Pre-startup,Phase,2017-07-01,2018-01-01,#c8e6c9
Startup,Phase,2018-01-02,2018-12-30,#a5d6a7
Growth,Phase,2019-01-01,2019-12-30,#fb8c00
" ",Value Mission,2017-07-01,2017-09-01,#c8e6c9
Minimum Value Product,Phase,2017-09-02,2018-01-01,#a5d6a7
Product Market Fit,Phase,2018-01-02,2018-07-30,#fb8c00
Scaling,Phase,2018-08-01,2018-12-30,#DD4B39
1-217.0,category 2,2019-12-27,2019-12-27,#90caf9
3-200,category 1,2019-12-25,2019-12-25,#1565c0")
data <- read.csv(text="event,group,start,end,color
Pre-startup,Phase,2017-07-01,2018-01-01,#c8e6c9
Startup,Phase,2018-01-02,2018-12-30,#a5d6a7
Growth,Phase,2019-01-01,2019-12-30,#fb8c00
..,Value Mission,2017-07-01,2017-09-01,#c8e6c9
Minimum Value Product,Phase,2017-09-02,2018-01-01,#a5d6a7
Product Market Fit,Phase,2018-01-02,2018-07-30,#fb8c00
Scaling,Phase,2018-08-01,2018-12-30,#DD4B39
1-217.0,category 2,2019-12-27,2019-12-27,#90caf9
3-200,category 1,2019-12-25,2019-12-25,#1565c0")
vistime(data)
data <- read.csv(text="event,group,start,end,color
Pre-startup,Phase,2017-07-01,2018-01-01,#c8e6c9
Startup,Phase,2018-01-02,2018-12-30,#a5d6a7
Growth,Phase,2019-01-01,2019-12-30,#fb8c00
..,Value Mission,2017-07-01,2017-09-01,#c8e6c9
.., Minimum Value Product,2017-09-02,2018-01-01,#a5d6a7
Product Market Fit,Phase,2018-01-02,2018-07-30,#fb8c00
Scaling,Phase,2018-08-01,2018-12-30,#DD4B39
1-217.0,category 2,2019-12-27,2019-12-27,#90caf9
3-200,category 1,2019-12-25,2019-12-25,#1565c0")
vistime(data)
data <- read.csv(text="event,group,start,end,color
Pre-startup,Phase,2017-07-01,2018-01-01,#c8e6c9
Startup,Phase,2018-01-02,2018-12-30,#a5d6a7
Growth,Phase,2019-01-01,2019-12-30,#fb8c00
.., Value Mission,2017-07-01,2017-09-01,#c8e6c9
.., Minimum Value Product,2017-09-02,2018-01-01,#a5d6a7
.., Product Market Fit,2018-01-02,2018-07-30,#fb8c00
Scaling,Phase,2018-08-01,2018-12-30,#DD4B39
1-217.0,category 2,2019-12-27,2019-12-27,#90caf9
3-200,category 1,2019-12-25,2019-12-25,#1565c0")
vistime(data)
data <- read.csv(text="event,group,start,end,color
Pre-startup,Phase,2017-07-01,2018-01-01,#c8e6c9
Startup,Phase,2018-01-02,2018-12-30,#a5d6a7
Growth,Phase,2019-01-01,2019-12-30,#fb8c00
.., Value Mission,2017-07-01,2017-09-01,#c8e6c9
.., Minimum Value Product,2017-09-02,2018-01-01,#a5d6a7
.., Product Market Fit,2018-01-02,2018-07-30,#fb8c00
.., Scaling,2018-08-01,2018-12-30,#DD4B39
1-217.0,category 2,2019-12-27,2019-12-27,#90caf9
3-200,category 1,2019-12-25,2019-12-25,#1565c0")
vistime(data)
data <- read.csv(text="event,group,start,end,color
Pre-startup,Phase,2017-07-01,2018-01-01,#c8e6c9
Startup,Phase,2018-01-02,2018-12-30,#a5d6a7
Growth,Phase,2019-01-01,2019-12-30,#fb8c00
.., Value Mission,2017-07-01,2017-09-01,#c8e6c9
.., Minimum Value Product,2017-09-02,2018-01-01,#a5d6a7
.., Product Market Fit,2018-01-02,2018-07-30,#fb8c00
.., Scaling,2018-08-01,2018-12-30,#DD4B39")
vistime(data)
data <- read.csv(text="event,group,start,end,color
Pre-startup,Phase,2017-07-01,2018-01-01,#c8e6c9
Startup,Phase,2018-01-02,2018-12-30,#a5d6a7
Growth,Phase,2019-01-01,2019-12-30,#fb8c00
.., Value Mission,2017-07-01,2017-09-01,#c8e6c9
.., Minimum Value Product,2017-09-02,2018-01-01,#a5d6a7
.., Product Market Fit,2018-01-02,2018-07-30,#fb8c00
.., Scaling,2018-08-01,2018-12-31,#DD4B39,
.., Establishing, 2019-01-01, 2019-12-01")
vistime(data)
data <- read.csv(text="event,group,start,end,color
Pre-startup,Phase,2017-07-01,2018-01-01,#c8e6c9
Startup,Phase,2018-01-02,2018-12-30,#a5d6a7
Growth,Phase,2019-01-01,2019-12-30,#fb8c00
.., Value Mission,2017-07-01,2017-09-01,#c8e6c9
.., Minimum Value Product,2017-09-02,2018-01-01,#a5d6a7
.., Product Market Fit,2018-01-02,2018-07-30,#fb8c00
.., Scaling,2018-08-01,2018-12-31,#DD4B39,
.., Establishing, 2019-01-01, 2019-12-01, #DD4B39")
vistime(data)
data <- read.csv(text="event,group,start,end,color
Pre-startup,Phase,2017-07-01,2018-01-01,#c8e6c9
Startup,Phase,2018-01-02,2018-12-30,#a5d6a7
Growth,Phase,2019-01-01,2019-12-30,#fb8c00
.., Value Mission,2017-07-01,2017-09-01,#c8e6c9
.., Minimum Value Product,2017-09-02,2018-01-01,#a5d6a7
.., Product Market Fit,2018-01-02,2018-07-30,#fb8c00
.., Scaling,2018-08-01,2018-12-31,#DD4B39,
.., Establishing, 2019-01-01,2019-12-01, #DD4B39")
vistime(data)
data <- read.csv(text="event,group,start,end,color
Pre-startup,Phase,2017-07-01,2018-01-01,#c8e6c9
Startup,Phase,2018-01-02,2018-12-30,#a5d6a7
Growth,Phase,2019-01-01,2019-12-30,#fb8c00
.., Value Mission,2017-07-01,2017-09-01,#c8e6c9
.., Minimum Value Product,2017-09-02,2018-01-01,#a5d6a7
.., Product Market Fit,2018-01-02,2018-07-30,#fb8c00
.., Scaling,2018-08-01,2018-12-31,#DD4B39
.., Establishing,2019-01-01,2019-12-01,#DD4B39")
vistime(data)
Growth,Phase,2019-01-01,2019-12-30,#DD4B39"
data <- read.csv(text="event,group,start,end,color
Pre-startup,Phase,2017-07-01,2018-01-01,#c8e6c9
Startup,Phase,2018-01-02,2018-12-30,#a5d6a7
Growth,Phase,2019-01-01,2019-12-30,#DD4B39
.., Value Mission,2017-07-01,2017-09-01,#c8e6c9
.., Minimum Value Product,2017-09-02,2018-01-01,#c8e6c9
.., Product Market Fit,2018-01-02,2018-07-30,#a5d6a7
.., Scaling,2018-08-01,2018-12-31,#a5d6a7
.., Establishing,2019-01-01,2019-12-01,#DD4B39")
vistime(data)
data <- read.csv(text="event,group,start,end,color
Pre-startup,Phase,2017-07-01,2018-01-01,#c8e6c9
Startup,Phase,2018-01-02,2018-12-30,#fb8c00
Growth,Phase,2019-01-01,2019-12-30,#DD4B39
.., Value Mission,2017-07-01,2017-09-01,#c8e6c9
.., Minimum Value Product,2017-09-02,2018-01-01,#c8e6c9
.., Product Market Fit,2018-01-02,2018-07-30,#fb8c00
.., Scaling,2018-08-01,2018-12-31,#fb8c00
.., Establishing,2019-01-01,2019-12-01,#DD4B39")
vistime(data)
vistime(data, title = 'Precision Analytics Business Development Timeline')
plot = vistime(data, title = 'Precision Analytics Business Development Timeline')
ggave(plot, filename = 'plot.png')
pacman::p_load(vistime, ggplot2)
ggave(plot, filename = 'plot.png')
ggsave(plot, filename = 'plot.png')
pacman::p_load(vistime, plotly, htmlWidget)
pacman::p_load(vistime, plotly)
htmlwidgets::saveWidget(plot, "timeline.html")
setwd("~/joining")
?pandoc
unlink('joining_cache', recursive = TRUE)
unlink('joining_cache', recursive = TRUE)
knit_with_parameters('~/joining/joining.Rmd')
knitr('~/joining/joining.Rmd')
knit('~/joining/joining.Rmd')
?knitr
kable(list(day1, day2), 'html') %>%
kable_styling(full_width = F, font_size = 14)
kable(list(day1, day2), 'html') %>%
kable_styling(full_width = F, font_size = 14)
?right_join
?right_join
pacman::p_load(data.table, dplyr, tinytex, knitr)
# Scenario 1
day1 =  data.table(ID=LETTERS[1:12],
y1=round(rnorm(4),4))
day2 =  data.table(ID=LETTERS[6:17],
y2=round(rnorm(6),4))
day1
day2
left = left_join(day1, day2)
right = right_join(day1, day2)
inner= inner_join(day1, day2)
full = full_join(day1, day2)
semi = semi_join(day1, day2)
anti = anti_join(day1, day2)
left = left_join(day1, day2, by = 'ID')
right = right_join(day1, day2 , by = 'ID')
inner= inner_join(day1, day2, by = 'ID')
full = full_join(day1, day2, by = 'ID')
semi = semi_join(day1, day2, by = 'ID')
anti = anti_join(day1, day2, by = 'ID')
?right_join
right_join(x, y, by = NULL, copy = FALSE, suffix = c('.x', '.y'), ...)
day1 =  data.table(ID=LETTERS[1:12],
IQ=round(rnorm(12, 100, 15),2))
day2 =  data.table(ID=LETTERS[6:17],
IQ=round(rnorm(12, 100, 20),2))
# Scenario 1
day1 =  data.table(ID=LETTERS[1:12],
IQ=round(rnorm(12, 100, 15),2))
day2 =  data.table(ID=LETTERS[6:17],
IQ=round(rnorm(12, 100, 20),2))
day1
day2
left = left_join(day1, day2, by = 'ID')
right = right_join(day1, day2 , by = 'ID')
inner= inner_join(day1, day2, by = 'ID')
full = full_join(day1, day2, by = 'ID')
semi = semi_join(day1, day2, by = 'ID')
anti = anti_join(day1, day2, by = 'ID')
left
right
inner
full
semi
anti
inter = intersect(day1, day2, by = 'ID')
united = union(day1, day2, by = 'ID')
setdif = setdiff(day1, day2, by = 'ID')
inter
united
setdif
inter = dplyr::intersect(day1, day2, by = 'ID')
inter
united
setdif
inter
inter2 = dplyr::intersect(day1, day2)
inter2
rm(inter2)
left = left_join(day1, day2, by = 'ID')
right = right_join(day1, day2, by = 'ID')
inner= inner_join(day1, day2, by = 'ID')
full = full_join(day1, day2, by = 'ID')
semi = semi_join(day1, day2, by = 'ID')
anti = anti_join(day1, day2, by = 'ID')
left = left_join(day1, day2, by = 'ID')
right = right_join(day1, day2, by = 'ID')
inner= inner_join(day1, day2, by = 'ID')
full = full_join(day1, day2, by = 'ID')
semi = semi_join(day1, day2, by = 'ID')
anti = anti_join(day1, day2, by = 'ID')
kable(list(day1, day2), 'html') %>%
kable_styling(full_width = F, font_size = 18)
#install.packages('pacman')
pacman::p_load(knitr, kableExtra, formattable, data.table, dplyr,  rmarkdown, magrittr)
right_join(x, y, by = NULL, copy = FALSE, suffix = c('.x', '.y'), ...)
